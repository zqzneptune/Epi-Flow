# Beyond the Pipeline: Downstream Analysis Strategies

Epi-Flow is designed to excel at one critical task: transforming your raw sequencing data into a clean, high-quality set of alignments, peaks, and signal tracks for a single sample. The parameters and methods used represent a robust, community-accepted standard that suits *most* common situations.

However, scientific discovery rarely ends with a single peak file. Your specific biological question may require comparing conditions, assessing reproducibility across replicates, or refining your results with experiment-specific controls.

This guide showcases how to use the analysis-ready files generated by Epi-Flow—especially the final `clean.bam`—as the starting point for these essential downstream analyses. Think of the pipeline as the engine that prepares your materials perfectly; now, it's time to build your project.

---

## 1. Enhancing Peak Confidence with Input Controls

For ChIP-seq experiments, the gold standard for rigor is to compare the antibody-targeted sample against a matched "Input" control. This allows you to distinguish true protein-binding enrichment from background noise and local chromatin biases.

The pipeline processes your ChIP and Input samples independently. Once complete, you can use their final alignment files to perform a more rigorous, control-subtracted peak call.

**The Workflow:**
1.  Run Epi-Flow separately for your ChIP sample and your Input control sample.
2.  Use the final `clean.bam` files from both runs to manually call peaks with `macs3`, specifying the Input as a control.

**The Command:**
```bash
# Use the ChIP BAM as the "treatment" (-t) and the Input BAM as the "control" (-c)
macs3 callpeak \
  -t ./results_H3K27ac/alignments/H3K27ac_Rep1.clean.bam \
  -c ./results_Input/alignments/Input_Rep1.clean.bam \
  -f BAMPE \
  -g 2913022398 \
  -n H3K27ac_vs_Input_Peaks \
  --outdir ./analysis/H3K27ac_controlled_peaks
```
This produces a higher-confidence peak set that is statistically enriched over your experiment-specific background.

---

## 2. Validating Biological Reproducibility Across Replicates

Biological replicates are fundamental to robust science. Epi-Flow processes each replicate individually, and it is in the downstream analysis where you assess their consistency. There are two primary strategies, each answering a different question.

#### Strategy A: "What is the most comprehensive set of potential sites?" (Pooling)

If your replicates are high-quality, pooling their alignments creates a single, deeper dataset. This increases your statistical power to discover weaker or less-occupied sites.

**The Workflow:**
1.  Run Epi-Flow on each replicate.
2.  Merge the resulting `clean.bam` files with `samtools merge`.
3.  Call peaks on the merged BAM file.

**The Command:**
```bash
samtools merge -@ 8 \
  ./analysis/merged/CTCF_merged.bam \
  ./results/CTCF_Rep1/alignments/CTCF_Rep1.clean.bam \
  ./results/CTCF_Rep2/alignments/CTCF_Rep2.clean.bam

samtools index ./analysis/merged/CTCF_merged.bam

macs3 callpeak -t ./analysis/merged/CTCF_merged.bam -f BAMPE -g hs -n CTCF_merged_peaks ...
```

#### Strategy B: "What are the most reproducible, high-confidence sites?" (Concordance/IDR)

This is the most rigorous approach and the standard for publication-quality results. Here, you identify the peaks that are consistently present across replicates. The **Irreproducible Discovery Rate (IDR)** framework is the gold standard for this.

**The Workflow:**
1.  Run Epi-Flow on each replicate to generate independent peak sets.
2.  Use a tool like `idr` to compare the peak lists from your replicates.
3.  The output is a final set of peaks that pass a stringent reproducibility threshold, representing your most reliable findings.

---

## 3. Comparing Conditions: Differential Peak Analysis

Most research aims to understand change—what happens after a drug treatment, or in a mutant versus a wild-type? This requires a differential analysis to find sites that gain or lose signal between conditions.

This is a multi-sample statistical question that is performed *after* each sample has been processed by Epi-Flow. The pipeline provides the essential inputs for powerful R packages like **DiffBind**, **DESeq2**, and **edgeR**.

**The General Workflow (automated by packages like DiffBind):**
1.  **Process all samples** (e.g., Control-Rep1/2, Treatment-Rep1/2) through Epi-Flow.
2.  **Define a consensus peak set:** All unique peak regions from all samples are merged into a master list of potential sites.
3.  **Count reads in peaks:** For each sample, the number of reads in its `clean.bam` file that overlap each peak in the master list is counted. This builds a count matrix.
4.  **Perform statistical testing:** The count matrix is used to model the data and identify peaks with a statistically significant difference in reads between the "Control" and "Treatment" groups.

---

## 4. Refining Your Peak Set: Adjusting Sensitivity

The pipeline's default peak calling parameters are designed for a good balance of sensitivity and specificity. However, for exploratory analysis, you might want to see weaker, potential sites, or conversely, you might want only the absolute strongest ones.

Because Epi-Flow provides the final `clean.bam` file, you can easily re-run just the peak-calling step with different thresholds without re-processing the entire dataset.

**The Command:**
```bash
# For a MORE stringent peak set (fewer, stronger peaks), decrease the q-value
macs3 callpeak -t ./results/MySample/alignments/MySample.clean.bam -f BAMPE -g hs -n MySample_q0.01 -q 0.01

# For a LESS stringent peak set (more exploratory peaks), increase the q-value
macs3 callpeak -t ./results/MySample/alignments/MySample.clean.bam -f BAMPE -g hs -n MySample_q0.10 -q 0.10
```
This flexibility allows you to explore your data from multiple perspectives, ensuring you can tailor the final results to the specific goals of your project.